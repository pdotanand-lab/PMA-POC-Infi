# === Backend .env example ===
# Where whisper.cpp binary 'main' (or 'whisper') is located. Example: /usr/local/bin/whisper
WHISPER_BIN=whisper
# Path to Whisper GGUF model file (e.g., ggml-base.en.gguf or large-v3)
WHISPER_MODEL=/path/to/ggml-base.en.gguf

# Optional: extra args passed to whisper.cpp (e.g., --lang en -ovtt -oj -of)
WHISPER_ARGS=--language en -oj

# Ollama base URL
OLLAMA_BASE=http://localhost:11434
# LLM model to use for generation (ensure pulled in Ollama: e.g., llama3.1:8b, mistral, qwen2.5)
OLLAMA_MODEL=llama3.1:8b
# Embeddings model (ensure pulled in Ollama: nomic-embed-text is common)
OLLAMA_EMBED_MODEL=nomic-embed-text

# CORS for frontend dev server
CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# SQLite DB path (created automatically)
DATABASE_URL=sqlite:///./app.db
